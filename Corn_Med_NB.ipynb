{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWvLdlps-A2p"
      },
      "source": [
        "Install requirements for saving model as HDF5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGClIXF7Cm-B"
      },
      "source": [
        "!pip install -q pyyaml h5py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trraGPj1kx1L"
      },
      "source": [
        "Code for preparing Kaggle and downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8lWU5tegtT8",
        "outputId": "6cd6e8da-1b7e-4e4f-f8ad-cd39b48e0b06"
      },
      "source": [
        "!mkdir .kaggle\n",
        "!touch .kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"{YOUR_USERNAME}\",\"key\":\"{YOUR_KEY}\"}\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!mv .kaggle /root/\n",
        "!kaggle datasets download -d sohaibalam67/corn-disease"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading corn-disease.zip to /content\n",
            " 89% 89.0M/100M [00:02<00:00, 44.9MB/s]\n",
            "100% 100M/100M [00:02<00:00, 44.3MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAn88ZGg86Wm"
      },
      "source": [
        "Extract dataset and removing unnessecary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G995DByG3KpT"
      },
      "source": [
        "!unzip corn-disease.zip\n",
        "!rm -rf corn\n",
        "!rm -rf sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmzBvmi276A0"
      },
      "source": [
        "Additional : use this code to mount your google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7SRoiOHuKiB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjyHFhLK7yip"
      },
      "source": [
        "Model main code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNY_lZFYNyYA",
        "outputId": "ea7e0643-62c4-4953-ea10-ba61a78b562a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow.keras.layers as layers\n",
        "NUM_OF_CLASSES = 4\n",
        "NUM_OF_PICS = 3852\n",
        "BATCH_SIZE = 32\n",
        "IW = 256\n",
        "IH = 256\n",
        "dataset_dir = \"/content/Corn/\"\n",
        "gray_leaf_dataset = \"/content/Corn/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot/\"\n",
        "rust_dataset = \"/content/Corn/Corn_(maize)___Common_rust_/\"\n",
        "northern_leaf_dataset=\"/content/Corn/Corn_(maize)___Common_rust_/\"\n",
        "healthy_dataset = \"/content/Corn/Corn_(maize)___healthy/\"\n",
        "PIL.Image.open(\"/content/Corn/Corn_(maize)___healthy/07317e94-df27-4c29-bd69-6c5e54a0457d___R.S_HL 7998 copy.jpg\")\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir,validation_split=0.25,subset=\"training\",seed=8569,image_size=(IH,IW),batch_size=BATCH_SIZE)\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir,validation_split=0.25,subset=\"validation\",seed=8569,image_size=(IH,IW),batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "checkpoint_filepath = 'checkpoints/mdl.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "                             tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "                             tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(IH, IW, 3)),\n",
        "                             #tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
        "                             #tf.keras.layers.MaxPool2D(),\n",
        "                             tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "                             tf.keras.layers.MaxPool2D(),\n",
        "                             tf.keras.layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),\n",
        "                             tf.keras.layers.MaxPool2D(),\n",
        "                             tf.keras.layers.Conv2D(128,3,padding=\"same\",activation=\"relu\"),\n",
        "                             tf.keras.layers.MaxPool2D(),\n",
        "                             tf.keras.layers.Conv2D(256,3,padding=\"same\",activation=\"relu\"),\n",
        "                             tf.keras.layers.MaxPool2D(),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(512,activation=\"relu\"),\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(512,activation=\"relu\"),\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(4)\n",
        "                             \n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])\n",
        "EPOCHS = 8\n",
        "model.fit(train_dataset,validation_data=val_dataset,epochs=EPOCHS)\n",
        "model.save(\"mdl.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3852 files belonging to 4 classes.\n",
            "Using 2889 files for training.\n",
            "Found 3852 files belonging to 4 classes.\n",
            "Using 963 files for validation.\n",
            "Epoch 1/8\n",
            "91/91 [==============================] - 13s 140ms/step - loss: 0.9210 - accuracy: 0.5701 - val_loss: 0.5059 - val_accuracy: 0.8536\n",
            "Epoch 2/8\n",
            "91/91 [==============================] - 13s 140ms/step - loss: 0.4077 - accuracy: 0.8183 - val_loss: 0.2276 - val_accuracy: 0.8972\n",
            "Epoch 3/8\n",
            "91/91 [==============================] - 13s 139ms/step - loss: 0.3020 - accuracy: 0.8712 - val_loss: 0.2019 - val_accuracy: 0.9117\n",
            "Epoch 4/8\n",
            "91/91 [==============================] - 12s 137ms/step - loss: 0.2557 - accuracy: 0.8941 - val_loss: 0.3180 - val_accuracy: 0.8930\n",
            "Epoch 5/8\n",
            "91/91 [==============================] - 12s 136ms/step - loss: 0.3111 - accuracy: 0.8643 - val_loss: 0.2077 - val_accuracy: 0.9294\n",
            "Epoch 6/8\n",
            "91/91 [==============================] - 12s 136ms/step - loss: 0.2428 - accuracy: 0.9003 - val_loss: 0.1870 - val_accuracy: 0.9263\n",
            "Epoch 7/8\n",
            "91/91 [==============================] - 13s 138ms/step - loss: 0.2300 - accuracy: 0.9114 - val_loss: 0.2455 - val_accuracy: 0.9034\n",
            "Epoch 8/8\n",
            "91/91 [==============================] - 12s 137ms/step - loss: 0.1961 - accuracy: 0.9221 - val_loss: 0.2038 - val_accuracy: 0.9283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWn5izGt8gYR"
      },
      "source": [
        "Summary of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAUBkgIFJFwf",
        "outputId": "1dcd35be-367e-4487-8c55-f755c33637b8"
      },
      "source": [
        "mymodel = tf.keras.models.load_model(\"mdl.h5\")\n",
        "mymodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_24 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 256, 256, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_118 (MaxPoolin (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 128, 128, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_119 (MaxPoolin (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_120 (MaxPoolin (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_121 (Conv2D)          (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_121 (MaxPoolin (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_122 (MaxPoolin (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 9,046,436\n",
            "Trainable params: 9,046,436\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBVxoTCr9Vs_"
      },
      "source": [
        "Additional: Code for converting model to Lite for using on smartphones, embedded systems, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viGcbQsR-8HT"
      },
      "source": [
        "model = tf.keras.models.load_model('/path/to/')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"lite_mdl.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
